This  project - Voice and Vision Assistance Chatbot - EVA, integrates speech recognition, text-to-speech synthesis, and image analysis for interactive communication. 

The project utilizes Gradio package for UI, SpeechRecognition and OPENAI's Whisper-Large-V3 from GROQ API for speech-to-text conversion, and Google Text-to-Speech (gTTS) & ElevenLabs for text-to-speech output. 

The chatbot processes user queries from audio, text, or images and generates responses using the META's LLaMA-3.2-11B-Vision-Preview model. 

It also employs FFmpeg & Pydub for audio processing and Playsound for playback. 

The chatbot is designed to act as a medical assistant by analyzing images and responding with relevant medical advice.
